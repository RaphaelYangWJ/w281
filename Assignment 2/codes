## ================== Task 1 =======================
def interpolate_green(raw_img, offset_value):
    # Create an empty image container
    green_img = np.zeros_like(raw_img, dtype=np.float32)
    # Gain the row and col values
    row_loc, col_loc = raw_img.shape
    # Iterations
    for row_index in range(1, row_loc-1):
        for col_index in range(1, col_loc-1):
            # Replicate the green value to green_channel_matrix
            if (row_index + col_index + offset_value) % 2 == 0:
                green_img[row_index, col_index] = raw_img[row_index, col_index]
            # Perform interpolation for non-green value grid
            else:
                green_img[row_index, col_index] = (raw_img[row_index, col_index-1] + raw_img[row_index, col_index+1] + raw_img[row_index-1, col_index] + raw_img[row_index+1, col_index]) / 4
    # Crop the image
    green_img = green_img[1:-1, 1:-1]
    return green_img

def interpolate_redblue(raw_img, offset_pair):
    # Create an empty image container
    redblue_img = np.zeros_like(raw_img, dtype=np.float32)
    # Gain the row and col values
    row_loc, col_loc = raw_img.shape
    row_offset, col_offset = offset_pair
    
    # Iterations
    for row_index in range(1, row_loc-1):
        for col_index in range(1, col_loc-1):
            
            if (row_index + row_offset) % 2 == 0 and (col_index + col_offset) % 2 == 0:
                redblue_img[row_index, col_index] = (raw_img[row_index-1, col_index-1] + raw_img[row_index-1, col_index+1] + raw_img[row_index+1, col_index-1] + raw_img[row_index+1, col_index+1]) / 4
            
            elif (row_index + row_offset) % 2 != 0 and (col_index + col_offset) % 2 == 0:
                redblue_img[row_index, col_index] = (raw_img[row_index, col_index-1] + raw_img[row_index, col_index+1]) / 2
            
            elif (row_index + row_offset) % 2 == 0 and (col_index + col_offset) % 2 != 0:
                redblue_img[row_index, col_index] = (raw_img[row_index-1, col_index] + raw_img[row_index+1, col_index]) / 2  
            
            else:
                redblue_img[row_index, col_index] = raw_img[row_index, col_index]  

    # Crop the image
    redblue_img = redblue_img[1:-1, 1:-1]
    return redblue_img

# load images
test_img = plt.imread('./demosaicing/signs-small.png')
raw_img = plt.imread('./demosaicing/signs.png')

img = raw_img.copy()
# TODO: check img data type
print("Data Type: ", img.dtype)
print("Image Size: ", img.shape)
# convert the datat type if it is not float32
if img.dtype != np.float32:
    img = img.astype(np.float32) / 255

# Perform extractions
green_offset = 1
green_img = interpolate_green(img, green_offset)

blue_offset = [1, 1]
blue_img = interpolate_redblue(img, blue_offset)

red_offset = [0, 0]
red_img = interpolate_redblue(img, red_offset)

color_img = np.dstack((red_img, green_img, blue_img))
# Convert to unit8 for visualization
color_img = (color_img  * 255).astype(np.uint8)
print("Data Type: ", color_img.dtype)
print("Image Size: ", color_img.shape)
# Show the image
plt.imshow(color_img)
plt.show()




## ================== Task 2 =======================
# load images
img_list = sorted(glob('./denoising/*.png'))
img_ref = plt.imread(img_list[0])

# TODO: use a for-loop to load remaining images and check data types
for i,img in enumerate(img_list):
    print("Data Type: ", plt.imread(img).dtype)
    
def align_imgs(img1, img2, maxOffset):
    # TODO: use nested for-loops to compute the error for every possible
    # combination of x and y offsets, up to the maxOffset in each dimension
    # The function np.roll may be helpful for shifting the images relative to each other
    # For each offset, compute the squared error norm
    
    # set an initial value for the error and offset
    best_offset = (0, 0)
    best_error = float('+inf')
    
    # Iterate to compute the offsets
    for offset_y in range(-maxOffset, maxOffset + 1): # up and down
        for offset_x in range(-maxOffset, maxOffset + 1): # left and right
            # shift the image
            shifted_img = np.roll(img2, (offset_y, offset_x), axis = (0,1))
            # subtract
            difference = img1 - shifted_img
            # crop the valid region
            if offset_x >= 0 and offset_y >= 0:
                difference = difference[offset_y:,offset_x:]
            elif offset_x < 0 and offset_y >= 0:
                difference = difference[offset_y:,:offset_x]
            elif offset_x >= 0 and offset_y < 0:
                difference = difference[:offset_y,offset_x:]
            else:
                difference = difference[:offset_y,:offset_x]
    
            error = np.sum(difference**2)
            # record the result if it is best
            if error <= best_error:
                best_error = error
                best_offset = (offset_y, offset_x)
    
    
    return best_offset, best_error

def combine_imgs(img_list, offset_list):
    # TODO: for each image, shift it by the corresponding offset from align_imgs
    # Compute the mean across all offset images
    # Note that you do not need to make an array containing all images
    # It is computationally cheaper to add the weighted pixel values to a running sum image
    
    # create an image template matrix with zeros
    sum_img = plt.imread(img_list[0])
    
    # Iterate to add the shifted images to the sum_img
    for img_path, offset_params in zip(img_list[1:], offset_list):
        img = plt.imread(img_path)
        offset_y = offset_params[0][0]
        offset_x = offset_params[0][1]
        img_shift = np.roll(img, (offset_y, offset_x), axis=(0, 1))
        sum_img += img_shift
    
    # compute the mean value
    composite_img = sum_img / len(img_list)
    
    return composite_img

# TODO: for each image in img_list, compute best_offset using align_imgs
# Use the resulting offset list to generate a composite image
offset_list = []
for img in img_list[1:]:
    # read image based on the path
    img_element = plt.imread(img)
    # check the data type and convert
    if img_element.dtype != np.float32:
        img_element = img_element.astype(np.float32) / 255
    # compute the alignments
    offset, best_error = align_imgs(img_ref, img_element, maxOffset=15)
    # append the results
    offset_list.append([offset, best_error])

# Combine images & convert to unit8
composite_img = combine_imgs(img_list, offset_list)
composite_img = (composite_img  * 255).astype(np.uint8)
# Show the image
plt.axis('off')
plt.figure(figsize = (20,10))
plt.imshow(composite_img)
plt.show()




## ================== Task 3 =======================
# load image
input_img = plt.imread('./white_balance/input.png')
# TODO: check img data type
print("Data Type: ", input_img.dtype)
# convert the datat type if it is not float32
if input_img.dtype != np.float32:
    input_img = input_img.astype(np.float32) / 255

def gray_world(input_img):
    # TODO: get average green value
    # compute scale factor for red and blue
    # rescale red and blue channels
    
    # Compute the mean values
    red_mean = np.mean(input_img[:, :, 0])
    green_mean = np.mean(input_img[:, :, 1])
    blue_mean = np.mean(input_img[:, :, 2])
    
    # Generate the scale factor based on the green mean value
    scaled_red_factor = green_mean / red_mean
    scaled_blue_factor = green_mean / blue_mean
    
    # Multiply the scaled factor to corresponding channels
    revised_red_channel = scaled_red_factor * input_img[:, :, 0]
    revised_blue_channel = scaled_blue_factor * input_img[:, :, 2]
    
    # stack the new channels to formulate RGB images
    wb_img = np.dstack((revised_red_channel,input_img[:, :, 1],revised_blue_channel))
    
    # Clip values for the range between [0,1]
    wb_img = np.clip(wb_img, 0, 1)
    
    # return the wb_img
    return wb_img

def white_patch(input_img):
    # TODO: get point(s) from user
    # compute scale factors for each color channel
    # rescale each color channel
    
    # Copy the image
    wb_img = input_img.copy()
    
    # Select the patch
    patch = input_img[100:101, 100:101]
    
    # Compute scale factors for each color channel
    scale_factor = 1 / np.mean(patch, axis=(0, 1))
    
    # scale all pixels in channels
    wb_img[:, :, 0] = scale_factor[0] * input_img[:, :, 0] # Red Channel
    wb_img[:, :, 1] = scale_factor[1] * input_img[:, :, 1] # Green Channel
    wb_img[:, :, 2] = scale_factor[2] * input_img[:, :, 2] # Blue Channel
    
    # Clip values for the range between [0,1]
    wb_img = np.clip(wb_img, 0, 1)
    
    # return the wb_img
    return wb_img

gray_world_output = gray_world(input_img)
white_patch_output = white_patch(input_img)

fig1 = plt.figure()
plt.imshow(gray_world_output)
plt.xticks(ticks=[])
plt.yticks(ticks=[])
plt.title('Gray-World')
plt.show()

fig2 = plt.figure()
plt.imshow(white_patch_output)
plt.xticks(ticks=[])
plt.yticks(ticks=[])
plt.title('White-Patch')
plt.show()







