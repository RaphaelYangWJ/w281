{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Playing with Frequencies\n",
    "\n",
    "MIDS W281: Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hybrid Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hybrid Teaser](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_4/objective1.png)\n",
    "\n",
    " ### Overview\n",
    " The goal of this part of the assignment is to create [hybrid images](http://olivalab.mit.edu/hybrid_gallery/gallery.html) using the approach described in the SIGGRAPH 2006 [paper](http://olivalab.mit.edu/publications/OlivaTorralb_Hybrid_Siggraph06.pdf) by Oliva, Torralba, and Schyns. Hybrid images are static images that change in interpretation as a function of the viewing distance. The basic idea is that high frequency tends to dominate perception when it is available, but, at a distance, only the low frequency part of the image can be seen. By blending the high-frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances.\n",
    "\n",
    " ### Description\n",
    " You are given a sample image of [Albert Einstein](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_3/al.png) and [Marlyn Monroe](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_3/mm.png). These images are already aligned such that the eyes are at the same location in the images.\n",
    "\n",
    " 1. Low-pass the image of Albert Einstein. For a low-pass filter, Oliva et al. suggests using a standard 2-D Gaussian filter. The size and sigma of the Gaussian filter can be decided with some experimentation. In the given example, we used a Gaussian filter of size 15 and sigma 8. **Hint: You can use create_2d_gaussian(size, std) function in utils.py to create a 2-D Gaussian filter of a given size and sigma.**  \n",
    "\n",
    " 2. High-pass filter the image of Marlyn Monroe. For a high-pass filter, the paper suggests using the impulse filter minus the Gaussian filter. This is the same method we used to create a high-pass filter [I - I<sub>b</sub>] in Part 1 of the previous assignment. For computing [I<sub>b</sub>] in this example, we used a Gaussian filter of size 9 and sigma 1.5. You can experiment with these values.  \n",
    " \n",
    " 3. Create a hybrid image by taking the average of the output images in the above two steps.  \n",
    "\n",
    "### Deliverables:\n",
    "\n",
    "- Python code creating hybrid images\n",
    "- The output hybrid image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes in an two images,  \n",
    "# uses the create_2d_gaussian method inside the utils script to create a 2D Gaussian filter\n",
    "# then passes these filters to scipy.ndimage's convolve function\n",
    "# finally, uses these blurred images to return a hybrid image\n",
    "\n",
    "def hybrid_image(im1, im2):\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the assignment images\n",
    "imfile1 ='images/al.png' \n",
    "imfile2 = 'images/mm.png'\n",
    "\n",
    "im1 = plt.imread(imfile1) # low sf\n",
    "im2 = plt.imread(imfile2) # high \n",
    "\n",
    "# hybrid images\n",
    "# TODO call hybrid_image to return a hybrid image\n",
    "\n",
    "# TODO show and save your resultant image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multiresolution Blending (a.k.a. the oraple!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multiresolution Teaser](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_4/objective2.png)\n",
    "\n",
    "### Overview\n",
    "The goal of this part of the assignment is to blend two images seamlessly using multi-resolution blending, as described in the 1983 [paper](http://persci.mit.edu/pub_pdfs/spline83.pdf) by Burt and Adelson. In this method, blending occurs at multiple scales so that low-frequency content is blended smoothly over a wide area, and high-frequency content is blended sharply over a narrow area. This is achieved using _image stacks_, which are similar to _image pyramids_. In an image pyramid, for each level of the pyramid the image is downsampled (so that each pyramid level gets smaller and smaller). In a stack, the images for each level are progressively blurred, but not downsampled, so that each pyramid level contains fewer high frequencies but is still of the same size as the original image. Images in a stack can all be saved in one 3D matrix if the original image was grayscale.\n",
    "\n",
    "### Description\n",
    "\n",
    " 1. Implement a function that creates Gaussian and Laplacian stacks. To create the successive levels of the Gaussian stack, just apply the Gaussian filter at each level, but do not downsample. The first image in a Gaussian stack is the original image. Therefore, the last image in an n-level stack is an image that is blurred n-1 number of times. For a Laplacian stack, take the difference between the successive levels of the Gaussian stacks. Additonally, the last level of a n-level Laplacian stack is an image blurred n-1 number of times (i.e., the remainder low-frequency information not included in the previous levels). In this project, you must implement your own Gaussian and Laplacian stacks. Do not use the pyrDown or pyrUp functions in Python.  \n",
    " ***Hint: Compare your final output image to the provided objective output.  If it does not look correct, consider how you calculate the difference between the successive levels of the Gaussian stack to calculate your Laplacian stack (which level is subtracted from another)***\n",
    " \n",
    " 2. Display the six levels of the Laplacian stack in a single Python plot. Use the output hybrid image from Part 1 for creating the stacks in this deliverable. Notice the first level and the last level of the Laplacian stack. The first level (high frequency) will look like Marlyn Monroe and the last level (low frequency) will look like Albert Einstein. The size and sigma of the Gaussian kernel used for blurring can be the same as in Part 1.\n",
    " \n",
    " 3. Now write code in order to use your Gaussian and Laplacian stacks for blending two images together. For this, we have included the two sample images from the paper (of an [apple](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_3/apple.png) and an [orange](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_3/orange.png)), and a [mask](https://raw.githubusercontent.com/W281/fileRepository/main/Assignments/Assignment_3/mask.png) image. First, create Laplacian stacks for the two input images (six levels is sufficient). Additionally, create a Gaussian stack for your mask. In our example, we used a Gaussian kernel of size 17 and sigma 3. Display the stacks for the two input images and the mask.\n",
    " \n",
    " 4. Create a blended image, B, using the Laplacian stacks of the two images (image X and image Y) and the Gaussian stack of the mask. The intensity of the blended image at location (i,j) can be computed using the following formula,\n",
    " \n",
    "     $$B(i,j)=\\sum_{l=1}^{n} [GM_l(i,j) \\times LX_l(i,j) + (1 - GM_l(i,j)) \\times LY_l(i,j)]$$ \n",
    "     \n",
    "     where $GM_l$, $LX_l$, and $LY_l$ are the $l$ th level of: the Gaussian stack for the mask image, the Laplacian stacks of image X, and the Laplacian stacks of image Y and $n$ is the number of levels in the stack.\n",
    " \n",
    " 5. Finally normalize the image pixels in Image B between 0 and 1 before saving. **Hint: You can use the `normalize_img(img)` function in utils.py**\n",
    "\n",
    "\n",
    "### Deliverables:\n",
    "\n",
    " - Python code for Gaussian and Laplacian stacks\n",
    " - Python code for image blending\n",
    " - A plot displaying the six levels of Laplacian stacks for the hybrid image\n",
    " - Plots displaying the six levels of Laplacian stacks for the two sample images\n",
    " - Plots displaying the six levels of Gaussian stacks for the mask image\n",
    " - The blended image, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack visualization\n",
    "def visualize_stack(in_stack, title):\n",
    "    # set the number of levels\n",
    "    # create multi-row figure\n",
    "    # add images to the figure from the stack\n",
    "    # don't forget to set the cmap, vmin, vmax, and axis off\n",
    "    # add titles to the plot\n",
    "    pass \n",
    "    \n",
    "# takes in a single channel\n",
    "def gaussian_and_laplacian_stack(img, levels):\n",
    "    # create 2D Gaussian\n",
    "    # for each level\n",
    "    # apply Gaussian and append to Gaussian stack\n",
    "    # subtract current from previous Gaussian in stack\n",
    "    # append result to Laplacian stack\n",
    "    pass\n",
    "\n",
    "def collapse_laplacian_stack(laplacian_stack):\n",
    "    # add all the layers of the laplacian stack together\n",
    "    pass\n",
    "\n",
    "def create_blended_stack(ls1, ls2, gr):\n",
    "    # for each level\n",
    "    # compute a weighted sum of the images in both stacks at that level\n",
    "    pass\n",
    "\n",
    "def multires_blending(img1, img2, mask):\n",
    "    # create Gaussian and Laplacian stacks for both images and the mask\n",
    "    # create blended stack of image Laplacian stacks\n",
    "    # use mask Gaussian stack as weights\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = plt.imread(\"images/apple.png\")\n",
    "img2 = plt.imread(\"images/orange.png\")\n",
    "mask = plt.imread(\"images/mask.png\")\n",
    "\n",
    "# create stacks for hybrid, apple, orange, mask\n",
    "gs_h, ls_h = gaussian_and_laplacian_stack(hybrid, 6)\n",
    "gs_a, ls_a = gaussian_and_laplacian_stack(img1, 6)\n",
    "gs_o, ls_o = gaussian_and_laplacian_stack(img2, 6)\n",
    "gs_m, _ = gaussian_and_laplacian_stack(mask, 6)\n",
    "\n",
    "# visualize all the stacks\n",
    "visualize_stack(ls_h, title='laplacian hybrid')\n",
    "visualize_stack(ls_a, title='laplacian apple')\n",
    "visualize_stack(ls_o, title='laplacian orange')\n",
    "visualize_stack(gs_m, title='gaussian mask')\n",
    "\n",
    "blended = normalize_img(multires_blending(img1, img2, mask, clip=False))\n",
    "\n",
    "plt.imsave(\"out_oraple.png\", blended, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "This assignment is inspired from Image Manipulation, Computer Vision and Computational Photography course at EECS UC Berkeley."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "994d27049b6d1b3a4dc8007fc39d9d11e995dbfa516d084782a5acb2c2c0d3bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
