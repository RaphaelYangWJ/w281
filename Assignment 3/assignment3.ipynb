{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Image Filtering\n",
    "\n",
    "MIDS W281: Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Convolution\n",
    "\n",
    "![Convolution Teaser](https://raw.githubusercontent.com/W281/fileRepository/main/convolution_teaser.png)\n",
    "\n",
    "### Overview\n",
    "A Gaussian filter reduces the high frequency content and retains mostly the low frequencies. When we convolve a Gaussian filter with an image, this is called low-pass filtering. Alternatively, if we want a high-pass image, we can subtract a low-pass filtered version from the original image to get only the high frequencies. \n",
    "\n",
    "An image often looks sharper if it has more high frequencies. We can increase the high-frequency content by adding the high-pass image to the original using a method called \"unsharp mask filtering\". In this part, you will create an \"unsharp mask filter\" that performs image sharpening. Perform your experiment on the [Taj.png](./images/taj.png) image, shown above.\n",
    "\n",
    "### Description\n",
    "1. Implement a python function to perform convolution given an image and a convolution kernel filter as inputs. The convolution kernel can be either a 2-D or 1-D kernel. The input image is grayscale (single channel). Do not use `scipy.ndimage.convolve` or any other equivalent function for convolution. Implement your own. Your function should return a convolved image of the same size as the input image. To handle the pixels at the edges of the image, obtain missing information by wrapping around to the opposite edge. For example, in order to compute the values in the first row, you will consider the values in the the *last* row, first row, and second row. Similarly, in order to compute the values in the first column, consider the values in the *last* column, first column, and second column.\n",
    "\n",
    "2. Use the above convolution function to blur the Taj.png image [I] using the following Gaussian kernel [g], producing the output convolved image [I<sub>b</sub>]\n",
    "\n",
    " $$\\begin{bmatrix} 0.0751 & 0.1238 & 0.0751 \\\\ 0.1238 & 0.2042 & 0.1238 \\\\ 0.0751 & 0.1238 & 0.0751 \\end{bmatrix}$$\n",
    "  &emsp;&emsp;\n",
    " \n",
    "3. Subtract the blurred image [I<sub>b</sub>] from original image [I], to get the high frequency image: [I<sub>h</sub> = I - I<sub>b</sub>]. Then add the high frequency image [I<sub>h</sub>] back to the original [I] to get the unsharp mask image: [I<sub>s</sub> = I + I<sub>h</sub>]\n",
    "\n",
    "4. Design a single convolution kernel [h] that will output the unsharp mask image [I<sub>s</sub>] when convolved with the original image [I]\n",
    "\n",
    "5. Convolve the original image [I] with this kernel [h]. Let's call the output image [I'<sub>s</sub>].  \n",
    "\n",
    "6. Compute the root mean square error (RMSE) between [I'<sub>s</sub>] and [I<sub>s</sub>].  Your error should be very close to zero (i.e. 10^-15 to 10^-16 floating point error, depending on your setup)\n",
    "### Deliverables:\n",
    "\n",
    "- Python code for convolution\n",
    "- All three output images [I<sub>b</sub>, I<sub>s</sub>, I'<sub>s</sub>] and the unsharp mask convolution filter [h]\n",
    "- Root mean square error between [I'<sub>s</sub>] and [I<sub>s</sub>]  ***(Use the provided, `rmse` function to calculate this)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(img1, img2):\n",
    "    \"\"\"Calculate and return Root mean squared error\"\"\"\n",
    "    return np.sqrt(np.mean(np.square(img1 - img2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a convolution function that takes in a grayscale image and a kernel as input\n",
    "# and returns the convolved image (as a numpy array)\n",
    "\n",
    "def convolution(in_im, h):\n",
    "    pass # remove this line and implement your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell (and more as needed) to implement your code and display + save the three output images:\n",
    "# blurred image [I_b]\n",
    "# sharpened image without convolution  [I_s]\n",
    "# sharpened image with convolution [I_sp]\n",
    "\n",
    "im_path = 'images/taj.png'\n",
    "im = plt.imread(im_path)\n",
    "\n",
    "# blurring filter provided by the assignment\n",
    "h = np.array([[0.0751, 0.1238, 0.0751], \n",
    "              [0.1238, 0.2042, 0.1238],\n",
    "              [0.0751, 0.1238, 0.0751]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Deconvolution\n",
    "\n",
    "![Deconvolution Teaser](https://raw.githubusercontent.com/W281/fileRepository/main/deconvolution_teaser.png)\n",
    "\n",
    "### Overview\n",
    "The process to reverse convolution is called deconvolution. Typically this requires some knowledge or estimate of how the convolved image was created (i.e. knowing or guessing the convolution filter). In this part you will estimate the original image from a convolved image and a known convolution filter. Because deconvolution is a memory intensive process, we will work with a 1-D kernel in this part.\n",
    "\n",
    "### Description  \n",
    "\n",
    "1. Start with the original image [I] and your convolution function from Part 1. First, blur the image [I] by convolving each row with the following 1-D kernel [g<sub>1</sub>] to produce a convolved image [I<sub>conv</sub>]\n",
    " $$\\begin{bmatrix} 0.274 & 0.452 & 0.274 \\end{bmatrix}$$  \n",
    "\n",
    "2. Write a new python function `deconvolution` which takes in a grayscale image and a 1-D kernel and returns the original deconvolved image. For this, you will need to formulate the problem as \n",
    "\n",
    " $$y=Ax$$\n",
    " \n",
    "    where $y$ is an Nx1 vector derived from a row of the input image, $A$ is an NxN matrix constructed by repeating the 1-D kernel for each pixel, and $x$ is an Nx1 vector corresponding to the unknown row of the deconvolved image. N is the total number of pixels in one row of the image.\n",
    "\n",
    "    ***Note that this formulation is only for one row, you must compute the original intensity for each row. Make sure to handle the boundary pixels correctly when constructing A (i.e. the first and the last rows of A). Use the same wrap-around method that was used Part 1. If the boundary conditions are not handled correctly, you will get artifacts in the resulting deconvolved image.***\n",
    "\n",
    "3. Use your deconvolution method on [I<sub>conv</sub>] and [g<sub>1</sub>] to produce the output image [I<sub>deconv</sub>]\n",
    "\n",
    "4. Compare the original image [I] and the deconvolved image [I<sub>deconv</sub>] in terms of root mean square error (RMSE). Your error should be very close to zero (i.e. 10^-13 to 10^-14 floating point error, depending on your setup)\n",
    "\n",
    "### Deliverables:\n",
    "\n",
    " - Python code for deconvolution\n",
    " - Deconvolved image [I<sub>deconv</sub>]\n",
    " - Root mean square error between [I] and [I<sub>deconv</sub>]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deconvolution function that takes in an image and a kernel as input\n",
    "# and returns the deconvolved image (as a numpy array)\n",
    "\n",
    "def deconvolution(in_im, h):\n",
    "    pass # remove this line and implement your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell (and more as needed) to implement your code and display + save the two output images:\n",
    "# blurred image [I_conv]\n",
    "# deconvolved image [I_deconv]\n",
    "# RMSE between I and I_deconv\n",
    "\n",
    "im_path = 'images/taj.png'\n",
    "im = plt.imread(im_path)\n",
    "\n",
    "# blurring filter provided by the assignment\n",
    "h = np.array([0.274, 0.452, 0.274])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
